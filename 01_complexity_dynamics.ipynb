{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper 1: The First Law of Complexodynamics\n",
    "## Scott Aaronson\n",
    "\n",
    "### Implementation: Cellular Automata and Entropy Growth\n",
    "\n",
    "This notebook demonstrates how complexity and entropy increase in closed systems using cellular automata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import entropy\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D Cellular Automaton (Rule 30 - Chaotic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule_30(left, center, right):\n",
    "    \"\"\"Rule 30: Generates complex, chaotic patterns\"\"\"\n",
    "    pattern = (left << 2) | (center << 1) | right\n",
    "    rule = 30\n",
    "    return (rule >> pattern) & 1\n",
    "\n",
    "def evolve_ca(initial_state, steps, rule_func):\n",
    "    \"\"\"Evolve cellular automaton\"\"\"\n",
    "    size = len(initial_state)\n",
    "    history = np.zeros((steps, size), dtype=int)\n",
    "    history[0] = initial_state\n",
    "    \n",
    "    for t in range(1, steps):\n",
    "        for i in range(size):\n",
    "            left = history[t-1, (i-1) % size]\n",
    "            center = history[t-1, i]\n",
    "            right = history[t-1, (i+1) % size]\n",
    "            history[t, i] = rule_func(left, center, right)\n",
    "    \n",
    "    return history\n",
    "\n",
    "# Simple initial state\n",
    "size = 100\n",
    "initial = np.zeros(size, dtype=int)\n",
    "initial[size // 2] = 1  # Single cell in center\n",
    "\n",
    "# Evolve\n",
    "steps = 100\n",
    "evolution = evolve_ca(initial, steps, rule_30)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(evolution, cmap='binary', interpolation='nearest')\n",
    "plt.title('Rule 30 Cellular Automaton - Complexity Growth from Simple Initial State')\n",
    "plt.xlabel('Cell Position')\n",
    "plt.ylabel('Time Step')\n",
    "plt.colorbar(label='State')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Complexity Growth via Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_entropy_over_time(history):\n",
    "    \"\"\"Measure Shannon entropy at each time step\"\"\"\n",
    "    entropies = []\n",
    "    \n",
    "    for t in range(len(history)):\n",
    "        state = history[t]\n",
    "        # Calculate probability distribution\n",
    "        unique, counts = np.unique(state, return_counts=True)\n",
    "        probs = counts / len(state)\n",
    "        ent = entropy(probs, base=2)\n",
    "        entropies.append(ent)\n",
    "    \n",
    "    return np.array(entropies)\n",
    "\n",
    "def measure_spatial_complexity(history):\n",
    "    \"\"\"Measure spatial pattern complexity (number of transitions)\"\"\"\n",
    "    complexities = []\n",
    "    \n",
    "    for t in range(len(history)):\n",
    "        state = history[t]\n",
    "        # Count transitions between adjacent cells\n",
    "        transitions = np.sum(np.abs(np.diff(state)))\n",
    "        complexities.append(transitions)\n",
    "    \n",
    "    return np.array(complexities)\n",
    "\n",
    "entropies = measure_entropy_over_time(evolution)\n",
    "complexities = measure_spatial_complexity(evolution)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "ax1.plot(entropies, linewidth=2)\n",
    "ax1.set_xlabel('Time Step')\n",
    "ax1.set_ylabel('Shannon Entropy (bits)')\n",
    "ax1.set_title('Entropy Growth Over Time')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.plot(complexities, linewidth=2, color='orange')\n",
    "ax2.set_xlabel('Time Step')\n",
    "ax2.set_ylabel('Spatial Complexity (transitions)')\n",
    "ax2.set_title('Spatial Pattern Complexity')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Initial Entropy: {entropies[0]:.4f} bits\")\n",
    "print(f\"Final Entropy: {entropies[-1]:.4f} bits\")\n",
    "print(f\"Entropy Increase: {entropies[-1] - entropies[0]:.4f} bits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Coffee Automaton: Irreversible Mixing\n",
    "\n",
    "Demonstrating that simple initial states evolve to complex patterns (like cream mixing in coffee) but the reverse is improbable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diffusion_2d(grid, steps, diffusion_rate=0.1):\n",
    "    \"\"\"Simple 2D diffusion simulation\"\"\"\n",
    "    history = [grid.copy()]\n",
    "    \n",
    "    for _ in range(steps):\n",
    "        new_grid = grid.copy()\n",
    "        h, w = grid.shape\n",
    "        \n",
    "        for i in range(1, h-1):\n",
    "            for j in range(1, w-1):\n",
    "                # Average with neighbors\n",
    "                neighbors = (\n",
    "                    grid[i-1, j] + grid[i+1, j] + \n",
    "                    grid[i, j-1] + grid[i, j+1]\n",
    "                ) / 4\n",
    "                new_grid[i, j] = (\n",
    "                    (1 - diffusion_rate) * grid[i, j] + \n",
    "                    diffusion_rate * neighbors\n",
    "                )\n",
    "        \n",
    "        grid = new_grid\n",
    "        history.append(grid.copy())\n",
    "    \n",
    "    return np.array(history)\n",
    "\n",
    "# Create initial state: concentrated \"cream\" in coffee\n",
    "size = 50\n",
    "grid = np.zeros((size, size))\n",
    "grid[20:30, 20:30] = 1.0  # Concentrated region\n",
    "\n",
    "# Simulate mixing\n",
    "mixing_history = diffusion_2d(grid, steps=50, diffusion_rate=0.2)\n",
    "\n",
    "# Visualize mixing process\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "timesteps = [0, 5, 10, 15, 20, 30, 40, 50]\n",
    "\n",
    "for idx, (ax, t) in enumerate(zip(axes.flat, timesteps)):\n",
    "    ax.imshow(mixing_history[t], cmap='YlOrBr', vmin=0, vmax=1)\n",
    "    ax.set_title(f'Time Step {t}')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('Irreversible Mixing: The Coffee Automaton', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Measure entropy growth in mixing\n",
    "mixing_entropies = []\n",
    "for t in range(len(mixing_history)):\n",
    "    flat = mixing_history[t].flatten()\n",
    "    # Discretize for entropy calculation\n",
    "    bins = np.histogram(flat, bins=20)[0]\n",
    "    probs = bins[bins > 0] / bins.sum()\n",
    "    mixing_entropies.append(entropy(probs, base=2))\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(mixing_entropies, linewidth=2)\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Spatial Entropy (bits)')\n",
    "plt.title('Entropy Increases During Mixing (Second Law)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nKey Insight: Simple concentrated state â†’ Complex mixed state\")\n",
    "print(f\"This process is irreversible: you can't unmix coffee!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Complexity Growth**: Simple initial states evolve into complex patterns\n",
    "2. **Entropy Increase**: Closed systems tend toward higher entropy (Second Law)\n",
    "3. **Irreversibility**: Complex states are unlikely to spontaneously return to simple states\n",
    "4. **Computational Irreversibility**: The Coffee Automaton demonstrates fundamental limits\n",
    "\n",
    "This connects to deep learning through:\n",
    "- Understanding of information theory\n",
    "- Complexity of learned representations\n",
    "- Entropy in loss functions and regularization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
